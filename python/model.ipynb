{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aman Kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Aman Kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6494 - auc: 0.5805 - loss: 0.7727 - val_accuracy: 0.7605 - val_auc: 0.7069 - val_loss: 0.7033 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - auc: 0.6581 - loss: 0.6654 - val_accuracy: 0.7615 - val_auc: 0.7113 - val_loss: 0.6471 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7458 - auc: 0.6809 - loss: 0.6617 - val_accuracy: 0.7595 - val_auc: 0.7120 - val_loss: 0.6333 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7635 - auc: 0.6960 - loss: 0.6417 - val_accuracy: 0.7625 - val_auc: 0.7068 - val_loss: 0.6309 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - auc: 0.7057 - loss: 0.6344 - val_accuracy: 0.7620 - val_auc: 0.7078 - val_loss: 0.6263 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7708 - auc: 0.6980 - loss: 0.6270 - val_accuracy: 0.7660 - val_auc: 0.7138 - val_loss: 0.6222 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7731 - auc: 0.7134 - loss: 0.6162 - val_accuracy: 0.7675 - val_auc: 0.7127 - val_loss: 0.6185 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - auc: 0.7196 - loss: 0.6082 - val_accuracy: 0.7655 - val_auc: 0.7080 - val_loss: 0.6207 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7763 - auc: 0.7326 - loss: 0.5993 - val_accuracy: 0.7680 - val_auc: 0.7096 - val_loss: 0.6135 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7669 - auc: 0.7322 - loss: 0.6032 - val_accuracy: 0.7710 - val_auc: 0.7134 - val_loss: 0.6100 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7654 - auc: 0.7238 - loss: 0.6032 - val_accuracy: 0.7730 - val_auc: 0.7134 - val_loss: 0.6070 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - auc: 0.7363 - loss: 0.6003 - val_accuracy: 0.7750 - val_auc: 0.7099 - val_loss: 0.6055 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - auc: 0.7308 - loss: 0.5867 - val_accuracy: 0.7680 - val_auc: 0.7080 - val_loss: 0.6036 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - auc: 0.7302 - loss: 0.5967 - val_accuracy: 0.7650 - val_auc: 0.7061 - val_loss: 0.6016 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - auc: 0.7475 - loss: 0.5778 - val_accuracy: 0.7675 - val_auc: 0.7073 - val_loss: 0.5988 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7702 - auc: 0.7383 - loss: 0.5803 - val_accuracy: 0.7695 - val_auc: 0.7035 - val_loss: 0.5992 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7687 - auc: 0.7424 - loss: 0.5792 - val_accuracy: 0.7645 - val_auc: 0.7059 - val_loss: 0.5964 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - auc: 0.7483 - loss: 0.5657 - val_accuracy: 0.7680 - val_auc: 0.7030 - val_loss: 0.5934 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - auc: 0.7538 - loss: 0.5564 - val_accuracy: 0.7655 - val_auc: 0.7052 - val_loss: 0.5898 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - auc: 0.7573 - loss: 0.5565 - val_accuracy: 0.7665 - val_auc: 0.7058 - val_loss: 0.5877 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - auc: 0.7666 - loss: 0.5523 - val_accuracy: 0.7675 - val_auc: 0.7016 - val_loss: 0.5867 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - auc: 0.7543 - loss: 0.5561 - val_accuracy: 0.7720 - val_auc: 0.7084 - val_loss: 0.5841 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7714 - auc: 0.7558 - loss: 0.5565 - val_accuracy: 0.7695 - val_auc: 0.7075 - val_loss: 0.5812 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - auc: 0.7597 - loss: 0.5476 - val_accuracy: 0.7700 - val_auc: 0.6991 - val_loss: 0.5826 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - auc: 0.7610 - loss: 0.5561 - val_accuracy: 0.7685 - val_auc: 0.7054 - val_loss: 0.5783 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - auc: 0.7727 - loss: 0.5331 - val_accuracy: 0.7755 - val_auc: 0.7075 - val_loss: 0.5763 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - auc: 0.7621 - loss: 0.5453 - val_accuracy: 0.7700 - val_auc: 0.6985 - val_loss: 0.5778 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7856 - auc: 0.7738 - loss: 0.5272 - val_accuracy: 0.7685 - val_auc: 0.7096 - val_loss: 0.5734 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - auc: 0.7572 - loss: 0.5469 - val_accuracy: 0.7680 - val_auc: 0.6999 - val_loss: 0.5755 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7796 - auc: 0.7646 - loss: 0.5344 - val_accuracy: 0.7615 - val_auc: 0.6973 - val_loss: 0.5754 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7806 - auc: 0.7744 - loss: 0.5269 - val_accuracy: 0.7640 - val_auc: 0.6996 - val_loss: 0.5726 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - auc: 0.7712 - loss: 0.5334 - val_accuracy: 0.7575 - val_auc: 0.6986 - val_loss: 0.5746 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - auc: 0.7738 - loss: 0.5195 - val_accuracy: 0.7680 - val_auc: 0.6958 - val_loss: 0.5745 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7803 - auc: 0.7788 - loss: 0.5186 - val_accuracy: 0.7715 - val_auc: 0.6990 - val_loss: 0.5687 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7757 - auc: 0.7658 - loss: 0.5304 - val_accuracy: 0.7695 - val_auc: 0.7031 - val_loss: 0.5682 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7826 - auc: 0.7724 - loss: 0.5268 - val_accuracy: 0.7665 - val_auc: 0.6994 - val_loss: 0.5700 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - auc: 0.7817 - loss: 0.5058 - val_accuracy: 0.7645 - val_auc: 0.6949 - val_loss: 0.5698 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - auc: 0.7736 - loss: 0.5233 - val_accuracy: 0.7610 - val_auc: 0.6947 - val_loss: 0.5705 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7773 - auc: 0.7674 - loss: 0.5187 - val_accuracy: 0.7625 - val_auc: 0.6913 - val_loss: 0.5687 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7818 - auc: 0.7930 - loss: 0.4980 - val_accuracy: 0.7635 - val_auc: 0.6979 - val_loss: 0.5652 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - auc: 0.7792 - loss: 0.5134 - val_accuracy: 0.7655 - val_auc: 0.7008 - val_loss: 0.5642 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - auc: 0.7928 - loss: 0.4984 - val_accuracy: 0.7740 - val_auc: 0.6995 - val_loss: 0.5633 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - auc: 0.7857 - loss: 0.5058 - val_accuracy: 0.7605 - val_auc: 0.7021 - val_loss: 0.5639 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7837 - auc: 0.7867 - loss: 0.5054 - val_accuracy: 0.7690 - val_auc: 0.6966 - val_loss: 0.5656 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7860 - auc: 0.7853 - loss: 0.5078 - val_accuracy: 0.7655 - val_auc: 0.6941 - val_loss: 0.5657 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - auc: 0.7907 - loss: 0.4976 - val_accuracy: 0.7680 - val_auc: 0.6950 - val_loss: 0.5645 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - auc: 0.7939 - loss: 0.4967 - val_accuracy: 0.7685 - val_auc: 0.6935 - val_loss: 0.5652 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - auc: 0.7884 - loss: 0.4928 - val_accuracy: 0.7690 - val_auc: 0.6955 - val_loss: 0.5643 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7935 - auc: 0.8055 - loss: 0.4878 - val_accuracy: 0.7710 - val_auc: 0.6978 - val_loss: 0.5637 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8009 - auc: 0.7984 - loss: 0.4886 - val_accuracy: 0.7685 - val_auc: 0.6928 - val_loss: 0.5655 - learning_rate: 1.2500e-04\n",
      "Model saved in Keras native format at 'saved_model/my_model.keras'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved in HDF5 format at 'saved_model/my_model.h5'\n",
      "Preprocessing artifacts saved.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Best Threshold on Validation Set: 0.40, F1: 0.8669\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step\n",
      "\n",
      "Final Test Metrics:\n",
      "Accuracy: 0.7630\n",
      "Precision: 0.7686\n",
      "F1 Score: 0.8632\n",
      "AUC: 0.6704\n",
      "MSE: 0.1726\n",
      "True Positive Percentage: 76.86%\n",
      "False Positive Percentage: 23.14%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, mean_squared_error, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "realistic_file_path = \"C:\\\\Users\\\\Aman Kumar\\\\OneDrive\\\\Desktop\\\\Agenix\\\\aadvanced_meaningful_funnel_conversion_data.csv\"\n",
    "data = pd.read_csv(realistic_file_path)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = [\"Traffic_Source\", \"Purchase_History\", \"Device_Type\", \"Time_of_Day\", \"Discount_Usage\"]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(\"Conversion\", axis=1)\n",
    "y = data[\"Conversion\"]\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split into Train/Validation/Test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train_series, y_val_series = train_test_split(X_trainval, y_trainval, stratify=y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train = y_train_series.to_numpy()\n",
    "y_val = y_val_series.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Model Definition\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.0005), input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.0005)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.0005)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Callbacks for Early Stopping and LR Reduction\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the Model\n",
    "os.makedirs(\"saved_model\", exist_ok=True)\n",
    "\n",
    "# Save in Keras format (recommended)\n",
    "model.save(\"saved_model/my_model.keras\")\n",
    "print(\"Model saved in Keras native format at 'saved_model/my_model.keras'\")\n",
    "\n",
    "# Save in HDF5 format\n",
    "model.save(\"saved_model/my_model.h5\")\n",
    "print(\"Model saved in HDF5 format at 'saved_model/my_model.h5'\")\n",
    "\n",
    "# Save preprocessing artifacts\n",
    "with open(\"saved_model/label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "with open(\"saved_model/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Preprocessing artifacts saved.\")\n",
    "\n",
    "# Threshold Tuning\n",
    "y_val_pred_prob = model.predict(X_val).ravel()\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0.0\n",
    "\n",
    "for threshold in np.arange(0.1, 1.0, 0.01):\n",
    "    y_val_pred = (y_val_pred_prob > threshold).astype(int)\n",
    "    f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Best Threshold on Validation Set: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
    "\n",
    "# Final Evaluation\n",
    "y_test_pred_prob = model.predict(X_test).ravel()\n",
    "y_test_pred = (y_test_pred_prob > best_threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "mse = mean_squared_error(y_test, y_test_pred_prob)\n",
    "f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "\n",
    "# Calculate TP and FP\n",
    "true_positive_count = sum((y_test_pred == 1) & (y_test == 1))\n",
    "false_positive_count = sum((y_test_pred == 1) & (y_test == 0))\n",
    "total_positive_predictions = len(y_test_pred[y_test_pred == 1])\n",
    "\n",
    "true_positive_percentage = (true_positive_count / total_positive_predictions) * 100 if total_positive_predictions > 0 else 0\n",
    "false_positive_percentage = (false_positive_count / total_positive_predictions) * 100 if total_positive_predictions > 0 else 0\n",
    "\n",
    "print(\"\\nFinal Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"True Positive Percentage: {true_positive_percentage:.2f}%\")\n",
    "print(f\"False Positive Percentage: {false_positive_percentage:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
